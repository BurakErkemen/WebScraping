import requests
from bs4 import BeautifulSoup

# KullanÄ±cÄ±dan bilgi al (sadece marka, model, yÄ±l)
marka = input("Marka: ").lower()
model = input("Model: ").lower()
yil = input("YÄ±l: ")

# URL oluÅŸtur (motor, kasa, yakÄ±t olmadan)
url = f"https://otoendeks.com/arabam-ne-kadar/{marka}-{model}/{yil}"
print(f"\n[+] Sayfa aÃ§Ä±lÄ±yor: {url}")

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

# SayfayÄ± Ã§ek
response = requests.get(url, headers=headers)
if response.status_code != 200:
    print("âŒ Sayfa yÃ¼klenemedi:", response.status_code)
    exit()

soup = BeautifulSoup(response.text, "html.parser")

# AraÃ§ seÃ§eneklerini bul
items = soup.find_all("div", class_="itm-link-container")
if not items:
    print("âŒ AraÃ§ seÃ§enekleri bulunamadÄ±.")
    exit()

print("\nğŸ” Bulunan AraÃ§ SeÃ§enekleri:\n")
araÃ§lar = []
for i, item in enumerate(items):
    a = item.find("a", class_="pc")
    if not a:
        continue
    href = a.get("href")
    text_main = a.find("span", class_="itm-link-main-txt").text.strip()
    text_sub = a.find("span", class_="itm-link-sub-txt").text.strip()
    print(f"{i+1}. {text_main} | {text_sub}")
    araÃ§lar.append(("https://otoendeks.com" + href, text_main, text_sub))

# KullanÄ±cÄ±dan seÃ§im al
secim = int(input("\nSeÃ§mek istediÄŸiniz aracÄ±n numarasÄ±nÄ± girin: ")) - 1
secilen_url = araÃ§lar[secim][0]
print(f"\n[+] SeÃ§ilen araÃ§ URL'si: {secilen_url}")

# SeÃ§ilen aracÄ±n sayfasÄ±nÄ± Ã§ek
response2 = requests.get(secilen_url, headers=headers)
if response2.status_code != 200:
    print("âŒ SeÃ§ilen sayfa yÃ¼klenemedi.")
    exit()

soup2 = BeautifulSoup(response2.text, "html.parser")

# "Devam Et" linkini yakala
devam_div = soup2.find("div", class_="col-12 col-lg-6 offset-lg-3")
if devam_div:
    a_tag = devam_div.find("a", id="devam_et")
    if a_tag:
        devam_href = "https://otoendeks.com" + a_tag.get("href")
        print(f"[+] Devam Et linki bulundu: {devam_href}")
    else:
        print("âŒ 'Devam Et' linki bulunamadÄ±.")
        exit()
else:
    print("âŒ Devam Et container bulunamadÄ±.")
    exit()

# Devam Et sayfasÄ±nÄ± Ã§ek (tramer giriÅŸi olan sayfa)
response3 = requests.get(devam_href, headers=headers)
if response3.status_code != 200:
    print("âŒ Tramer sayfasÄ± yÃ¼klenemedi.")
    exit()

# Tramer input'undan linkin temelini oluÅŸtur
sonuc_url = devam_href + "-sonuc"
print(f"[+] SonuÃ§ sayfasÄ±: {sonuc_url}")

# SonuÃ§ sayfasÄ±nÄ± Ã§ek
response4 = requests.get(sonuc_url, headers=headers)
if response4.status_code != 200:
    print("âŒ SonuÃ§ sayfasÄ± yÃ¼klenemedi.")
    exit()

soup4 = BeautifulSoup(response4.text, "html.parser")

# SonuÃ§ bilgilerini Ã§Ä±kar
print("\nğŸ“Š OtoEndeks DeÄŸer Bilgileri:")

try:
    arac = soup4.find("h1", class_="scontent-deger").text.strip()
    otoendeks = soup4.find("span", class_="dgr").text.strip()
    kasko = soup4.find_all("span", class_="ext-scontent-deger")[1].text.strip()

    print("AraÃ§:", arac)
    print("Otoendeks DeÄŸeri:", otoendeks)
    print("Kasko DeÄŸeri:", kasko)
except Exception as e:
    print("âŒ Bilgiler alÄ±namadÄ± â€” HTML yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir.")
    print("Hata:", e)
